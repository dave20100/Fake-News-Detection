\chapter{Ocena eksperymentalna}
\section{Cel Badań}
Celem badań było sprawdzenie jak popularne algorytmy uczenia maszynowego radzą sobie z rozwiązaniem problemu 
klasyfikacji informacji jako prawdziwe lub nieprawdziwe. W celu sprawdzenia ich efektywności należało zbadać
takie cechy jak:
\begin{itemize}
    \item czas fazy uczenia,
    \item czas fazy predykcji,
    \item poprawność modelu (\textit{accuracy})
    \item odchylenie standardowe poprawności modelu.
\end{itemize}
Poprawność oraz odchylenie standardowe modelu została zbadana metodą K-krotnej walidacji krzyżowej. 
Metoda ta polega na podzieleniu zbioru danych na wybraną liczbę podzbiorów, a następnie wykorzystanie jednego
z nich jako dane treningowe a resztę jako testowe. Operację tą wykonuje się tyle razy ile wynosi liczba podzbiorów,
końcowe wyniki tej metody to średnia poprawność badań oraz odchylenie standardowe. Wartość odchylenia standardowego
pozwala określić jak bardzo poprawność danej metody jest zależna od danych treningowych. 
W badaniach głównym sprawdzanym elementem było to, jak zmiana długości ngramów, na które podzielony
został tekst przed wektoryzacją wpływa na wyniki algorytmów i odnalezienie takiego rozmiaru, który
daje najlepsze wyniki. 

Do badania wybrano pięć popularnych algorytmów uczenia maszynowego: 
\begin{itemize}
    \item \textit{k}-NN - K najbliższych sąsiadów,
    \item SVM - maszyna wektorów nośnych,
    \item Naive Bayes,
    \item RF - las losowy,
    \item MLP - wielowarstwowy perceptron.
\end{itemize} 
\section{Warunki przeprowadzonego eksperymentu}
Badania zostały wykonane na komputerze stacjonarnym o następującej specyfikacji:
\begin{itemize}
    \item system operacyjny Windows 10 Pro w wersji 10.0.19041,
    \item procesor AMD Ryzen 5 3600,
    \item pamięć RAM 16 GB.
\end{itemize}
Wszystkie badania były wykonywane w jednakowych warunkach, aby można było 
je w prosty sposób porównywać. 

Dane badawcze to zbiór pod nazwą ``ISOT Fake News Dataset'' przygotowany przez uczelnię w 
Kanadzie ``Univerity of Victoria''. Zawiera on 12600 artykułów prawdziwych pochodzących ze strony
internetowej Reuters.com oraz 12600 artykułów nieprawdziwych zebranych z niewiarygodnych źródeł
oznaczonych przez organizację do sprawdzania faktów Politifact. Tematyka artykułów to głównie polityka i wiadomości 
ze świata. Teksty zawarte w zbiorze zostały wstępnie przygotowane, jednak błędy znajdujące się w nieprawdziwych 
artykułach pozostały. Średnia długość artykułów ze zbioru wynosi 2469 znaków a najdłuższy z nich składa się z 51794.
Ponieważ artykuł o takim rozmiarze niesie ze sobą zbyt dużą ilość informacji, przed wykonaniem badań zostają usunięte 
artykuły posiadające ponad 5000 znaków. Zbiór został pobrany w dniu 16 czerwca 2020 z witryny znajdującej się 
pod adresem \url{https://www.uvic.ca/}.~\cite{ISOT}

Algorytmy \textit{k}-NN, RF oraz Naive Bayes zostały zbadane na rozmiarach ngramów od 1 do 10, natomiast
MLP i SVC od 1 do 5 z powodu dużej złożoności obliczeniowej przy większym rozmiarze. Podczas 
wykonywania walidacji krzyżowej zbiór danych był dzielony na 5 podzbiorów na każdym z nich wykonywana była kolejno 
wektoryzacja oraz redukcja wymiarowości obiektem StandardScaler z biblioteki scikit-learn.
\section{Wyniki}
W opisanych poniżej wynikach, każdy z algorytmów został zbadany pod kątem trzech cech. 
\begin{table}[H]
    \centering
    \caption{Wyniki algorytmu \textit{k}-NN wektoryzacja metodą Bag of words}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{ | l | c | c | c | c | c | c | c | c | c | c |}
        \hline
        Rozmiar ngramu & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10  \\ \hline
        Poprawność & 73.54\% & 80.07\% & 60.5\% & 48.63\% & 46.81\% & 46.61\% & 46.6\% & 55.38\% & 52.38\% & 52.36\%  \\ \hline
        Odchylenie standardowe & 5.12\% & 5.13\% & 4.83\% & 1.71\% & 0.39\% & 0.47\% & 0.49\% & 19.39\% & 5.56\% & 5.54\%  \\ \hline
        Czas fazy uczenia & 0.003s & 0.022s & 0.059s & 0.099s & 0.102s & 0.121s & 0.126s & 0.129s & 0.122s & 0.129s  \\ \hline
        Czas fazy predykcji & 27.221s & 180.565s & 312.157s & 221.672s & 137.788s & 91.407s & 67.833s & 54.803s & 45.88s & 40.02s  \\ \hline
    \end{tabular}
    }
\end{table}

\begin{table}[H]
    \centering
    \caption{Wyniki algorytmu \textit{k}-NN wektoryzacja metodą TFIDF}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{ | l | c | c | c | c | c | c | c | c | c | c |}
        \hline
        Rozmiar ngramu & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10  \\ \hline
        Poprawność & 76.0\% & 69.91\% & 60.38\% & 53.64\% & 46.74\% & 53.47\% & 52.37\% & 52.37\% & 52.37\% & 55.72\%   \\ \hline
        Odchylenie standardowe & 1.92\% & 5.34\% & 6.14\% & 9.74\% & 0.6\% & 6.82\% & 5.48\% & 5.46\% & 5.46\% & 7.92\%  \\ \hline
        Czas fazy uczenia & 0.003s & 0.024s & 0.067s & 0.092s & 0.112s & 0.111s & 0.122s & 0.123s & 0.127s & 0.129s \\ \hline
        Czas fazy predykcji & 27.168s & 186.84s & 321.7s & 220.716s & 141.115s & 93.327s & 68.613s & 46.536s & 47.467s & 37.644s  \\ \hline
    \end{tabular}
    }
\end{table}

\begin{table}[H]
    \centering
    \caption{Wyniki algorytmu RF wektoryzacja metodą Bag of words}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{ | l | c | c | c | c | c | c | c | c | c | c |}
        \hline
        Rozmiar ngramu & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\ \hline
        Poprawność & 83.41\% & 97.72\% & 99.29\% & 99.5\% & 99.22\% & 98.87\% & 98.4\% & 98.12\% & 97.88\% & 97.52\%  \\ \hline
        Odchylenie standardowe & 2.6\% & 0.77\% & 0.8\% & 0.68\% & 1.22\% & 1.67\% & 2.25\% & 2.82\% & 2.7\% & 2.96\%  \\ \hline
        Czas fazy uczenia & 23.56s & 47.484s & 48.267s & 45.867s & 52.639s & 73.57s & 108.591s & 143.566s & 187.709s & 225.265s \\ \hline
        Czas fazy predykcji & 0.234s & 0.764s & 2.587s & 5.095s & 6.324s & 8.315s & 15.628s & 19.665s & 23.49s & 25.823s  \\ \hline
    \end{tabular}
    }
\end{table}

\begin{table}[H]
    \centering
    \caption{Wyniki algorytmu RF wektoryzacja metodą TFIDF}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{ | l | c | c | c | c | c | c | c | c | c | c |}
        \hline
        Rozmiar ngramu & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\ \hline
        Poprawność & 83.24\% & 97.76\% & 99.29\% & 99.51\% & 99.11\% & 98.77\% & 98.47\% & 98.17\% & 97.87\% & 97.32\%  \\ \hline
        Odchylenie standardowe & 2.76\% & 0.66\% & 0.44\% & 0.65\% & 1.15\% & 1.84\% & 2.26\% & 2.61\% & 3.01\% & 3.52\%  \\ \hline
        Czas fazy uczenia & 26.536s & 57.014s & 53.246s & 47.681s & 48.82s & 63.392s & 92.896s & 132.436s & 175.463s & 217.02s \\ \hline
        Czas fazy predykcji & 0.24s & 0.729s & 3.027s & 5.021s & 6.554s & 7.893s & 14.047s & 20.172s & 24.588s & 26.493s  \\ \hline
    \end{tabular}
    }
\end{table}

\begin{table}[H]
    \centering
    \caption{Wyniki algorytmu Naive Bayes wektoryzacja metodą Bag of words}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{ | l | c | c | c | c | c | c | c | c | c | c |}
        \hline
        Rozmiar ngramu & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\ \hline
        Poprawność & 67.23\% & 77.99\% & 81.75\% & 88.32\% & 91.05\% & 92.79\% & 93.91\% & 94.22\% & 94.38\% & 94.25\%  \\ \hline
        Odchylenie standardowe & 7.65\% & 10.74\% & 10.58\% & 2.43\% & 3.15\% & 3.33\% & 2.65\% & 2.5\% & 2.0\% & 1.54\%  \\ \hline
        Czas fazy uczenia & 0.005s & 0.031s & 0.102s & 0.147s & 0.201s & 0.377s & 0.551s & 0.692s & 0.837s & 1.027s \\ \hline
        Czas fazy predykcji & 0.003s & 0.016s & 0.047s & 0.072s & 0.095s & 0.182s & 0.299s & 0.362s & 0.382s & 0.41s  \\ \hline
    \end{tabular}
    }
\end{table}

\begin{table}[H]
    \centering
    \caption{Wyniki algorytmu Naive Bayes wektoryzacja metodą TFIDF}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{ | l | c | c | c | c | c | c | c | c | c | c |}
        \hline
        Rozmiar ngramu & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\ \hline
        Poprawność & 73.96\% & 80.52\% & 83.36\% & 87.9\% & 90.54\% & 92.53\% & 93.68\% & 94.04\% & 94.15\% & 93.95\%  \\ \hline
        Odchylenie standardowe & 7.8\% & 10.69\% & 10.28\% & 1.97\% & 3.79\% & 3.46\% & 2.23\% & 2.05\% & 1.91\% & 1.67\%  \\ \hline
        Czas fazy uczenia & 0.005s & 0.033s & 0.105s & 0.159s & 0.193s & 0.293s & 0.504s & 0.675s & 0.853s & 1.02s \\ \hline
        Czas fazy predykcji & 0.002s & 0.017s & 0.05s & 0.077s & 0.09s & 0.145s & 0.319s & 0.343s & 0.406s & 0.407s  \\ \hline
    \end{tabular}
    }
\end{table}

\begin{table}[H]
    \centering
    \caption{Wyniki algorytmu SVC wektoryzacja metodą Bag of words}
    \begin{tabular}{ | l | c | c | c | c | c |}
        \hline
        Rozmiar ngramu & 1 & 2 & 3 & 4 & 5 \\ \hline
        Poprawność & 79.48\% & 95.08\% & 94.88\% & 95.43\% & 96.11\%   \\ \hline
        Odchylenie standardowe & 7.06\% & 2.02\% & 3.71\% & 2.11\% & 1.56\%  \\ \hline
        Czas fazy uczenia & 14.175s & 319.6s & 2779.462s & 7282.055s & 10144.174s  \\ \hline
        Czas fazy predykcji & 8.18s & 127.618s & 716.666s & 1502.585s & 2534.03s  \\ \hline
    \end{tabular}
\end{table}

\begin{table}[H]
    \centering
    \caption{Wyniki algorytmu SVC wektoryzacja metodą TFIDF}
    \begin{tabular}{ | l | c | c | c | c | c |}
        \hline
        Rozmiar ngramu & 1 & 2 & 3 & 4 & 5   \\ \hline
        Poprawność & 77.32\% & 95.35\% & 96.54\% & 96.81\% & 97.14\% \\ \hline
        Odchylenie standardowe & 6.62\% & 1.77\% & 2.46\% & 1.85\% & 1.41\%  \\ \hline
        Czas fazy uczenia & 14.046s & 220.009s & 3068.672s & 8322.766s & 10384.898s \\ \hline
        Czas fazy predykcji & 8.008s & 106.538s & 751.689s & 1594.27s & 2286.608s  \\ \hline
    \end{tabular}
\end{table}

\begin{table}[H]
    \centering
    \caption{Wyniki algorytmu MLP wektoryzacja metodą Bag of words}
    \begin{tabular}{ | l | c | c | c | c | c |}
        \hline
        Rozmiar ngramu & 1 & 2 & 3 & 4 & 5  \\ \hline
        Poprawność & 79.6\% & 96.69\% & 97.91\% & 98.18\% & 97.76\%   \\ \hline
        Odchylenie standardowe & 4.71\% & 0.71\% & 0.5\% & 0.63\% & 0.75\%  \\ \hline
        Czas fazy uczenia & 32.655s & 22.982s & 115.108s & 544.161s & 2038.845s  \\ \hline
        Czas fazy predykcji & 0.039s & 0.11s & 0.373s & 1.085s & 2.444s  \\ \hline
    \end{tabular}
\end{table}

\begin{table}[H]
    \centering
    \caption{Wyniki algorytmu MLP wektoryzacja metodą TFIDF}
    \begin{tabular}{ | l | c | c | c | c | c |}
        \hline
        Rozmiar ngramu & 1 & 2 & 3 & 4 & 5   \\ \hline
        Poprawność & 79.8\% & 97.43\% & 98.6\% & 98.69\% & 98.09\%   \\ \hline
        Odchylenie standardowe & 4.54\% & 0.67\% & 0.62\% & 0.58\% & 0.7\%  \\ \hline
        Czas fazy uczenia & 16.176s & 22.159s & 111.424s & 520.082s & 1926.648s  \\ \hline
        Czas fazy predykcji & 0.034s & 0.113s & 0.38s & 0.911s & 2.133s  \\ \hline
    \end{tabular}
\end{table}
\section{Analiza wyników wraz z oceną statystyczną}


Wyniki zostały przeanalizowane pod kątem trzech badanych cech:

\begin{itemize}
    \item Poprawność
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{./Img/BOWAcc.png}
        \caption{Poprawność algorytmów wektoryzacja metodą Bag of words}
    \end{figure}
    
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{./Img/TFIDFAcc.png}
        \caption{Poprawność algorytmów wektoryzacja metodą TFIDF}
    \end{figure}
    
    Pod względem poprawności algorytmy sprawdziły się następująco:
    \begin{itemize}
        \item \textit{k}-NN -
        dla długości równej 1 algorytm osiąga wyniki większe od 70\%, jednak wraz 
        z podnoszeniem się jej zmniejsza się także poprawność. W przypadku obu metod 
        wektoryzacji rozmiary 5 i 6 dają wyniki poniżej 50\%, co oznacza, że są one gorsze 
        od predykcji wykonanej na podstawie rzutu monetą. Jest to związane 
        z overfittingiem będącym skutkiem podnoszenia się ilości cech. Najlepszym wynikiem w 
        przypadku \textit{k}-NN jest 80.07\% przy wykorzystaniu metody wektoryzacji Bag of words i rozmiarze równym 2,
        a najgorszym 46.60\%  przy wykorzystaniu metody Bag of words i rozmiaru 7,

        \item RF, SVC, MLP -        
        algorytmy te zachowują się w bardzo podobny sposób. Zwiększanie długości ngramów 
        do wartości 4 powoduje bardzo szybki wzrost efektywności do nawet 99.51\%, natomiast zmiana 
        długości ponad 4 prowadzi do powolnego spadku możliwości predykcyjnych, co może być 
        związane podobnie jak w przypadku algorytmu \textit{k}-NN z overfittingiem. Algorytmy te osiągają najlepsze 
        wyniki pod względem efektywności ze wszystkich badanych,
        \item Naive Bayes -
        Algorytm Naive Bayes zwiększa swoją poprawność w taki sposób jak RF, SVC oraz MLP 
        jednak robi to dużo wolniej i osiąga swoją szczytową poprawność dla długości równej 8 przy której 
        jest ona równa 96.56\%. Dalsze wydłużanie ngramów prowadzi do powolnego spadku możliwości predykcyjnych.
        Algorytm Naive Bayes osiąga najniższe wyniki w przypadku podziału na ngramy o długości równej 1, gdzie 
        poprawnie klasyfikuje tylko 67.23\% danych testowych.
    \end{itemize}
    \item Czasy fazy uczenia
        \begin{figure}[h!]
            \centering
            \includegraphics[width=0.8\textwidth]{./Img/BOWLearn.png}
            \caption{Czasy uczenia algorytmów}
        \end{figure}
    
    
        Pod względem czasu fazy uczenia algorytmy sprawdziły się następująco:
    
    \begin{itemize}
        \item \textit{k}-NN, Naive Bayes -
        Algorytmy \textit{k}-NN oraz Naive Bayes osiągnęły najlepsze wyniki czasu trwania fazy uczenia, która podczas 
        trwania całego badania nie była dłuższa niż jedna sekunda.
        Jest to spowodowane względnie prostymi operacjami wykonywanymi przez nie podczas tej fazy. 
        Zadaniem algorytmu \textit{k}-NN jest jedynie zapisanie wszystkich danych, natomiast Naive Bayes  
        oblicza prawdopodobieństwa na podstawie prostych kalkulacji wykonywanych podczas jednej iteracji,
        \item RF -
        czas trwania fazy uczenia dla algorytmu RF ulega niewielkiemu wydłużaniu podczas zmiany rozmiaru 
        ngramów, jednak podczas całego badania jest on przeciętny, przez co nie trwa zbyt długo, ale też nie jest szybki.
        Faza ta w tym przypadku polega na stworzeniu drzewa decyzyjnego jak najlepiej podejmującego decyzje. Czas ten nie
        ulega znacznemu wydłużeniu przy większej liczbie cech, ponieważ algorytm wybiera tylko najważniejsze z nich do stworzenia 
        drzewa,
        \item SVC, MLP -
        w przypadku obu tych algorytmów można zauważyć znacznie zwiększanie się czasu uczenia wraz ze zwiększaniem
        długości ngramów. Doprowadziło to w ich przypadku do ograniczenia badań tylko do długości równej 5,
        ponieważ czas tej fazy wynosił niemal 3 godziny. Takie wyniki powodują, że nieprawdopodobne jest 
        ich efektywne wykorzystanie w systemach rozpoznawania \textit{fake newsów}. 
    \end{itemize}
    \item Czasy fazy predykcji
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{./Img/BOWPredict.png}
        \caption{Czasy predykcji algorytmów}
    \end{figure}
    
    
    Pod względem czasu fazy predykcji algorytmy sprawdziły się następująco:
    
    \begin{itemize}
        \item \textit{k}-NN -
        predykcja tego algorytmu jest znacznie dłuższa niż faza uczenia i dla mniejszych długości ngramów trwa
        najdłużej. Początkowo zwiększanie długości powoduje wzrost czasu, jednak po osiągnięciu maksimum dla rozmiaru 3
        następuje powolna stabilizacja w kierunku około 40 sekund,
        \item RF -
        czas trwania fazy predykcji zwiększa się powoli do wartości 26.49 sekund. Spowodowane jest to zwiększaniem
        się drzewa decyzyjnego który jest trawersowany w celu podjęcia decyzji. Czas ten podobnie jak w przypadku 
        fazy uczenia jest przeciętny w porównaniu z innymi algorytmami,
        \item Naive Bayes -
        Jest to najszybszy algorytm zarówno pod względem fazy uczenia, jak i predykcji, której wykonanie 
        opiera się na wyliczeniu odpowiednich prawdopodobieństw będących dla maszyny bardzo prostym zadaniem,
        \item SVC -
        czas trwania fazy predykcji jest bardzo podobny do czasu uczenia. Użycie SVC trwa zbyt długo
        by mógł on być zaimplementowany w jakichkolwiek systemach,
        \item MLP -
        w porówaniu z fazą uczenia predykcja następuje bardzo szybko, ponieważ opiera się tylko
        na aktywacji odpowiednich neuronów w stworzonym wcześniej modelu. Jest on na drugim miejscu
        pod względem prędkości wykonywania predykcji.
    \end{itemize}
\end{itemize}




\section{Wnioski z badań}
Przeprowadzone badania pozwoliły na odnalezienie odpowiedzi na pytanie 
będące celem niniejszej pracy. Wykorzystanie algorytmów uczenia maszynowego 
w rozpoznawaniu fałszywych informacji skutkuje osiągnięciem bardzo optymistycznych wyników.
Z badanych w algorytmów jedynie algorytm \textit{k}-NN swoją efektywnością dla 
każdej długości ngramów nie pozwoliłby na pewne podjęcie decyzji, czy dany artykuł jest prawdziwy, czy też nie.
Może to być związane z bardzo dużą liczbą cech w tekście, co bardzo szybko prowadzi do tak zwanego 
overfittingu. 

Z powodu eksponencjalnego zwiększania się ilości cech wraz ze zwiększaniem długości ngramów, 
algorytmy takie jak SVC oraz MLP osiągają już dla długości równej 5 zbyt długie czasy trwania faz uczenia sięgające 
do 3 godzin. Czas taki nie pozwala na wykorzystanie ich w systemach detekcji \textit{fake newsów}, ponieważ
musiałyby one analizować dużą ilość artykułów, dla których bardzo duże znaczenie ma to jak 
szybko pojawią się na docelowej stronie internetowej bądź mediach społecznościowych.

Najlepszym z algorytmów okazał się RF, który dla ngramów o długości równej 4
osiągnął poprawność równą 99.82\%. Pomimo iż poprawność ta została prawie osiągnięta przez algorytmy
SVC oraz MLP to były one znacznie wolniejsze podczas fazy uczenia, a także podczas fazy 
predykcji w przypadku SVC. Szybszy od RF algorytm Naive Bayes również osiągnął zadowalające wyniki poprawności,
jednak wysokie wartości odchylenia standardowego pozwalają stwierdzić, że wynik jest mocno zależny od 
danych, na których się on uczy w przeciwieństwie do algorytmu RF.

Zauważono także, że wybór metody wektoryzacji ma niewielki wpływ na to jak dobrze wykorzystany algorytm 
sprawdzi się w wykonywaniu swojego zadania. Jeżeli chodzi o czas trwania poszczególnych faz to 
różnica w czasie wynosiła zazwyczaj poniżej paru sekund w przypadku dłuższych algorytmów lub poniżej 
sekundy w przypadku krótszych. Pod względem efektywności można także zauważyć niewielkie różnice,
które przeplatają się
wraz ze zmianą długości, z tego powodu nie jest możliwe określenie, która metoda jest lepsza.

Wykorzystanie technologii machine learningu do zadania detekcji \textit{fake newsów} 
może stanowić rozwiązanie problemów jakie niosą ze sobą fałszywe informacje. Ich automatyczna 
detekcja uchroniłaby miliony ludzi przed byciem oszukanym. 
